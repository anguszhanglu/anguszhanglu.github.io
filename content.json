{"meta":{"title":"鹭岛","subtitle":"my zone,my rule","description":"zhanglu","author":"zhanglu","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2018-04-25T11:39:15.000Z","updated":"2018-04-25T11:39:15.270Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"linux软件包管理,系统管理命令,,关闭防火墙及克隆虚拟机","slug":"linux软件包管理-系统管理命令-关闭防火墙及克隆虚拟机","date":"2017-06-06T12:27:01.000Z","updated":"2018-06-06T12:35:07.349Z","comments":true,"path":"2017/06/06/linux软件包管理-系统管理命令-关闭防火墙及克隆虚拟机/","link":"","permalink":"http://yoursite.com/2017/06/06/linux软件包管理-系统管理命令-关闭防火墙及克隆虚拟机/","excerpt":"","text":"1 linux软件包管理（安装，卸载，查询）1.1 Linux软件包介绍windows中所有的软件包不能直接Linux中使用,在Linux的软件包有如下几种：（1）源码包（脚本）–》特点：免费、开源 .src 编译安装极少使用（2）二进制包（rpm包，系统默认包）相当于windows中.exe主要操作命令如下：rpm (获取rpm包的方式：可以网上下载，安装镜像ISO文件)yum（依赖问题需要借助网络，会自动解析依赖）少数使用（3）压缩包 （绿色版.tar.giz）多数使用 1.2 rpm命令操作rpm包（1）安装： # rpm -ivh tree-1.5.3-3.el6.x86_64.rpm 用法： rpm -ivh 软件名(.rpm) 选项： -i install 代表安装 -vh 显示详细的进度 tree的作用：可以显示当前目录的结构（2）查看：# rpm -qa 查询当前系统中安装了哪些软件(已经安装好的rpm包) 选项： -q（--query）代表查询 -a --all # rpm -qa | grep jdk(非安装版查询不到) # rpm -qa | grep mysql （3）卸载：# rpm -e xcb-util-0.3.6-1.el6.i686 选项： -e 代表卸载 --erase 用法： rpm -e 软件名(.rpm) --nodeps --nodeps：(不验证依赖卸载) Don’t do a dependency check before installing or upgrading a package. 例如：$ sudo rpm -e tree-1.5.3-3.el6.x86_64 【注意】：先查询再卸载 【扩展】软件包的命名方式：zlib-devel-1.2.3-29.el6.x86_64.rpm软件名（zlib） 版本类型（devel：开发版 ；client:客户端）版本号（1.2.3） 发行号（29.el6） 硬件平台（x86_64：64位；i386：32位） 1.3 yum命令 在线安装 .rpm 安装 查询 卸载（1）说明： 前提是必须连接外网 用来解决rpm依赖性问题 方便、快捷、自动解析依赖（比如安装maven需要依赖jdk,yum会自动完成）（2）查询： # yum list //查看yum源上拥有的软件 # yum list installed | more //查看系统中已经安装好的rpm包 等同于 rpm -qa 注意：如上命令知道即可，yum源上安装包过多，浪费时间。可使用如下方式 $ sudo yum list installed | grep mysql # yum list updates | more //查询可以更新的软件 （3）安装： 格式：# yum install 软件名称 选项：install 后缀不需要加.rpm 可以直接使用命令 $ sudo yum install tree， 选项：-y , 表示直接自动确认：$ sudo -y yum install tree （4）卸载 # yum -y remove 软件名 $ sudo rpm -qa | grep tree 推荐做法：使用yum安装，然后rpm做查询和卸载（rpm不需要联网，速度更快） 2 系统管理命令（了解）1. top 查看系统资源，相当于window中的资源管理器每3s更新一次按q键退出浏览状态 2. Free 查看内存信息 可能用到选项： -m 以MB格式显示 3. df -l(小写L) 查看硬盘分区的使用信息4. ps -ef 查看系统进程ps -ef | grep java 查看所有java进程jps 同上（常用） 5. kill 杀死正在进行的进程 ——》结合jps一起使用选项 ：-进程pid号例如 ： kill -9 6. Ifconfig 查看系统中所有网卡的IP mac信息7. ping 检查网络质量和网络连接 ping 主机名/ip地址/域名 3 关闭防火墙和安全子系统原因：Hadoop HBase这样的分布式集群应用需要在联机应用（分布式）中，一般会关闭防火墙。防火墙默认情况下，出于安全考虑会限制一些应用的网络访问，为了保证多机通信的稳定，可以选择关闭防火墙 1.关闭防火墙并且不开机启动1).关闭Linux 防火墙 # service iptables status ##查看防火墙状态 iptables: Firewall is not running. # service iptables stop ##关闭防火墙 2).设置不开机启动防火墙 # chkconfig iptables off ##不随机启动 3).查看防火墙的开机启动设置 $ sudo chkconfig --list | grep iptables 2.关闭安全子系统# vi /etc/sysconfig/selinux SELINUX=disabled 4 克隆虚拟机 快照 VMware需要先关闭Linux系统 关机：init 0 ; poweroff ; halt; shutdown 重启：init 6 ; reboot 4.1 快照作用：相当于复活点操作：虚拟机-》快照-》拍摄快照，需要还原时需要使用时选择恢复快照即可 4.2 克隆作用：复制一台和目标虚拟机完全一致的虚拟机，比重新配置虚拟机速度快很多。步骤：虚拟机–》管理 –》克隆 —》虚拟机当前状态—》选择完整克隆—》 —》完成 修改：克隆出来的虚拟机，要修改主机名还有ip地址，关键是要修改网卡信息1、修改主机名 # vi /etc/sysconfig/network 2、修改ip地址，注意，这里修改的是新网卡的ip，且ip地址最后一位在在3~255之间，并不能重复 3、修改虚拟机、windows和的ip和主机机映射： # vi /etc/hosts 在原有基础上追加内容为： 192.168.47.4 myCentOs_02 保存即可 注意：配置的多台虚拟机因为需要互相通信，所以其hosts文件内容需要保持一致，且相互间配置对应的主机名和ip映射。且多台虚拟机所使用的用户名和密码必须一致(zxx,mofa),以保证多台虚拟机能够作为一个整体进行使用 4、修改网卡的信息（mac地址HWADDR） # vi /etc/udev/rules.d/70-persistent-net.rules 删除原来的网卡信息通过mac地址来区分，删除原来的信息，并将新的网卡的name信息改为eth0 5、修改ip,重命名网卡配置名称 # vi /etc/sysconfig/network-scripts/ifcfg-eth0 删除uuid、修改mac地址HWADDR（可直接删除） 6、# reboot 重启虚拟机（因为修改了主机名） 同时修改windows中主机映射，增加： C:\\Windows\\System32\\drivers\\etc\\hosts 192.168.7.55 java.apache.com 要求：搭建Hadoop集群的3台虚拟机的要求 主机名 ip地址 username password1 hadoop1 192.168.x.3 xxx 1234562 hadoop2 192.168.x.4 xxx 1234563 hadoop3 192.168.x.5 xxx 123456 所有节点上的主机映射都一样，都包含相互的IP和主机名映射信息192.168.x.3 hadoop1192.168.x.4 hadoop2192.168.x.5 hadoop3 所有节点检查以下内容： 1.关闭防火墙 $ sudo service iptables status iptables: Firewall is not running. 2.不随机启动防火墙 $ sudo chkconfig –list | grep iptables iptables 0:off 1:off 2:off 3:off 4:off 5:off 6:off 3.关闭安全子系统 $ cat /etc/sysconfig/selinux SELINUX=disabled 4.安装jdk 1.8","categories":[],"tags":[],"keywords":[]},{"title":"Hadoop完全分布式搭建","slug":"Hadoop完全分布式搭建","date":"2017-06-06T11:52:14.000Z","updated":"2018-06-06T12:15:14.395Z","comments":true,"path":"2017/06/06/Hadoop完全分布式搭建/","link":"","permalink":"http://yoursite.com/2017/06/06/Hadoop完全分布式搭建/","excerpt":"","text":"集群规划 -&gt; 不同的守护进程运行哪些节点 linux01 linux02 linux03 HDFS Namenode SecondaryNamenode Datanode Datanode Datanode Yarn Nodemanager Nodemanager Nodemanager RecourceManager Histrory HistroryServer 一、基本环境准备CentOS 6.5 hadoop 2.7.6 jdk1.8 1 配置IP和DNS 映射 主机名//检查主机名 $ cat /etc/sysconfig/network //检查IP 和DNS 网关 配置静态IP $ cat /etc/sysconfig/network-scripts/ifcfg-eth0 //检查主机映射 $ cat /etc/hosts -&gt;Linux C:\\Windows\\System32\\drivers\\etc\\hosts -&gt;Windows 2 关闭防火墙及安全子系统# service iptables stop # chkconfig iptables off 检查： # service iptables status 会有提示iptables: Firewall is not running. # chkconfig --list | grep iptables 0:off 1:off 2:off 3:off 4:off 5:off 6:off 关闭Linux安全子系统 # vi /etc/sysconfig/selinux 为了提高性能，可以考虑将启动方式调整为不带桌面 sudo vi /etc/inittab id:3:initdefault: 3 创建普通用户名并密码, 配置sudo权限1 查看是否存在用户普通用户,没有就创建,稍后要保证3台帐号密码相同# useradd hadoop # passwd hadoop 或 # echo 123456 | passwd --stdin hadoop 2 配置hadoop的sudo权限4 安装jdk1 卸载自带jdk# rpm -qa | grep jdk # rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.50.1.11.5.el6_3.x86_64 # rpm -e --nodeps java-1.7.0-openjdk-1.7.0.9-2.3.4.1.el6_3.x86_64 2 在/opt下创建并修改权限modules/ software/ # mkdir /opt/modules /opt/software # chmod -R 777 modules/ software/ 3 安装jdk解压jdk到modules # tar -zxvf /home/hadoop/jdk-7u67-linux-x64.tar.gz -C /opt/modules/ 配置Java环境变量 # vi /etc/profile #添加以下内容 #JAVA_HOME export JAVA_HOME=/opt/modules/jdk1.7.0_67 export PATH=$PATH:$JAVA_HOME/bin 生效配置 # source /etc/profile 检查Java环境变量 # java -version 5 系统和软件【3台】如果时克隆出来的需要执行# vi /etc/udev/rules.d/70-persistent-net.rules 删除克隆来的信息(也就是eth0) 并把eth1改为eth0 # vi /etc/sysconfig/network-scripts/ifcfg-eth0 删除UUID 修改HWADDR=当前的mac地址(与70-persistent-net.rules的mac地址相同) 修改IPADDR为对应的ip 6 配置主机映射 【三台都需要需要添加】# vi /etc/hosts 192.168.239.211 bigdata01.hadoop.com 192.168.239.212 bigdata02.hadoop.com192.168.239.213 bigdata03.hadoop.com 7.修改主机名修改每台主机的主机名为对应的名字重启 8.windows的映射 (C:\\Windows\\System32\\drivers\\etc\\hosts)192.168.239.211 bigdata01.hadoop.com 192.168.239.212 bigdata02.hadoop.com 192.168.239.213 bigdata03.hadoop.com ## 二、配置NTP服务 *.把linux01作为整个集群的时间同步服务器 *.集群中所有其他服务器都来这台服务器linux01同步时间 1.检查每台服务器所在的时区 $ date -R Thu, 23 Mar 2017 11:13:57 +0800 如果不是+0800,如要通过如下命令调整 # rm -rf /etc/localtime ---如果时区不是+0800 # ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 2.安装ntp服务# rpm -qa | grep ntp --查看ntp软件包是否已安装 ntp-4.2.6p5-1.el6.centos.x86_64 ntpdate-4.2.6p5-1.el6.centos.x86_64 如果没有以上两个,执行命令: yum -y install ntp (安装ntp) 3.修改ntp的配置文件（linux01.bigdata.com为第一台服务器的主机名,修改第一台）# vi /etc/ntp.conf 去掉第18行的# 修改成自己的网段 restrict 192.168.239.0 mask 255.255.255.0 nomodify notrap 注释掉以下几行（22行） #server 0.centos.pool.ntp.org iburst #server 1.centos.pool.ntp.org iburst #server 2.centos.pool.ntp.org iburst #server 3.centos.pool.ntp.org iburst CentsOS6.4 去掉第35 36行的注释 CentsOS6.5 36行去手动添加以下内容 server 127.127.1.0 #local clock fudge 127.127.1.0 stratum 10 4、同步服务器的时间（bigdata01.hadoop.com）# ntpdate 202.108.6.95 #操作这一步时关闭ntp服务 23 Mar 11:36:56 ntpdate[26856]: step time server 173.255.246.13 offset -12.240613 sec 5、启动ntp服务（默认式开始）PC1 root用户操作（bigdata01.hadoop.com） # service ntpd start # chkconfig ntpd on # chkconfig --list | grep ntpd ntpd 0:off 1:off 2:on 3:on 4:on 启动状态就可以了 # ntpdate 202.120.2.101 #测试 9 Jun 15:27:49 ntpdate[2689]: the NTP socket is in use, exiting #表示服务器1 作为时间服务器,同步时间不可用 #ntpd一旦开启就不能手动同步时间 6、如果另外两台的ntp的进程开启，那么需要关闭(对其他两台进行操作)# service --status-all | grep ntpd 查看ntpd服务是否开启 # chkconfig --list | grep ntpd 查看ntpd服务是否随开机启动 #如果服务可能开启 执行以下命令 # service ntpd stop # chkconfig ntpd off 7.第2、3台向第一台同步时间# ntpdate bigdata01.hadoop.com 18 Jan 23:01:34 ntpdate[2304]: step time server 192.168.239.211 offset -28768.643767 sec 8.制定周期性时间同步计划任务（PC2、PC3定时向PC1手动同步时间）在PC2 PC3每10分钟同步一次时间 # crontab -e */10 * * * * /usr/sbin/ntpdate bigdata01.hadoop.com [注意]：如果确实无法向第一台同步时间，请在交互窗口（可以同时设置3台时间）执行手动设置时间 # date -s &apos;2017/08/29 15:34:30&apos; 三、配置SSH免密钥登录切换为普通用户hadoop 使用普通用户操作 使用ssh登录的时候不需要用户名密码 $ sbin/start-dfs.sh 每个节点操作 $ ssh-keygen * 一直回车，生产当前主机的公钥和私钥(~/.ssh) //分发密钥（要向3台都发送） $ ssh-copy-id bigdata01.hadoop.com $ ssh-copy-id bigdata02.hadoop.com $ ssh-copy-id bigdata03.hadoop.com 测试:[hadoop@bigdata01 ~]$ ssh bigdata02.hadoop.com 测试失败，先删除.ssh目录，重做一遍 $ rm -r ~/.ssh 四、安装Hadoop1.下载上传到Linux并解压hadoop的.tar.gz$ tar -zxf hadoop-2.5.0.tar.gz -C /opt/modules/ 2.删除${HADOOP_HOME}/share/doc$ rm -rf doc/ 3.配置java环境支持在${HADOOP_HOME}/etc/hadoop在hadoop-env.sh mapred-env.sh yarn-env.sh中配置 JAVA_HOME=/opt/modules/jdk1.7.0_67 4. =======core-site.xml===&lt;!-- 指定第一台作为NameNode --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://bigdata01.hadoop.com:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/modules/hadoop-2.5.0/data&lt;/value&gt; &lt;/property&gt; 5. ============hdfs-site.xml===========&lt;!-- 分布式副本数设置为3 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;!-- secondarynamenode主机名 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;bigdata02.hadoop.com:50090&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode的web访问主机名:端口号 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address&lt;/name&gt; &lt;value&gt;bigdata01.hadoop.com:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- 关闭权限检查用户或用户组 --&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; 6.============mapred-site.xml============&lt;!-- 指定mapreducer向yarn提交 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;bigdata01.hadoop.com:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;bigdata01.hadoop.com:19888&lt;/value&gt; &lt;/property&gt; 7.==========yarn-site.xml============&lt;!-- 指定哪个节点作为resourcemanager --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;bigdata03.hadoop.com&lt;/value&gt; &lt;/property&gt; &lt;!-- 在mapreducer过程中启用shuffle --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 启用日志聚合 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 日志保存时间 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;86400&lt;/value&gt; &lt;/property&gt; =============================== 8配置slavesbigdata01.hadoop.com bigdata02.hadoop.com bigdata03.hadoop.com 【注意事项】：1.slaves中配置集群中所有的主机名 2.所有节点上的配置文件内容都是一样的 3.要按照集群规划配置所属进程 4.配置普通用户, 所有节点 有相同的帐号密码 四、分发(注意每个节点的权限问题： /opt/没有写权限)（bigdata01.hadoop.com）分发hadoop（已经配置好的）目录到其他两台(bigdata02和bigdata03)服务器上 scp -r bigdata01要复制的目录 bigdata02复制到的目录 $ scp -r /opt/modules/hadoop-2.5.0/ bigdata02.hadoop.com:/opt/modules/ $ scp -r /opt/modules/hadoop-2.5.0/ bigdata03.hadoop.com:/opt/modules/ 五、格式化Namenode在namenode所在的服务器linux01上,进行格式化${HADOOP_HOME}/bin $ bin/hdfs namendoe -format 【注意】1.先将PC1的hadoop配置目录分发到PC2和PC32.保证3台上的配置内容一模一样3.先确保将3台没有格式化信息4.最后格式化 六、启动进程在PC1上使用如下命令启动HDFS $ sbin/start-dfs.sh 在PC1上使用如下命令启动YARN $ sbin/start-yarn.sh 停止进程 在PC1上使用如下命令停止HDFS $ sbin/stop-dfs.sh 在PC3上使用如下命令停止YARN $ sbin/stop-yarn.sh 【注意】修改任何配置文件，请先停止所有进程，然后重新启动 七、检查启动是否正常3台上jps查看进程，参考之前的集群规划 PC1:28626 DataNode28883 NodeManager28989 Jps28531 NameNode7527 ResourceManager PC2:7528 DataNode7826 Jps7717 NodeManager7583 SecondaryNameNode PC37622 NodeManager7922 Jps7405 DataNode","categories":[],"tags":[],"keywords":[]},{"title":"伪分布搭建","slug":"伪分布搭建","date":"2017-06-06T10:58:01.000Z","updated":"2018-06-06T11:46:50.017Z","comments":true,"path":"2017/06/06/伪分布搭建/","link":"","permalink":"http://yoursite.com/2017/06/06/伪分布搭建/","excerpt":"","text":"伪分布的搭建环境准备1) 网络配置(主机名, 映射文件(服务器的, windows,), ip) 2) 关闭防火墙及安全子系统 3) 安装jdk 切换为普通用户 sudo chmod 777 /opt 创建/opt/modules /opt/software 搭建伪分布1) 解压安装hadoop【注意上传和解压过程中的用户权限问题】$ tar -zxvf /opt/software/hadoop-2.7.6.tar.gz -C /opt/modules/ 2) 配置hadoop的java环境支持， etc/hadoop目录下hadoop-env.sh mapred-env.sh yarn-env.sh 在这3个文件中都配置 export JAVA_HOME=/opt/modules/jdk1.8.0_112 3) 与hdfs相关的配置 etc/hadoopI）core-site.xml =============core-site.xml=================== &lt;!-- NameNode地址，访问入口 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://learn01.bigdata.com:8020&lt;/value&gt; &lt;/property&gt; &lt;!-- hadoop在运行时产生的文件，元数据在本地的存放目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/modules/hadoop-2.7.6/data&lt;/value&gt; &lt;/property&gt; ============================================ II) hdfs-site.xml =============hdfs-site.xml============ &lt;!--存放到hdfs上的文件的副本数，伪分布式配置为1 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; ====================================== 4) 格式化namenode只格式化一遍在${HADOOP_HOME}目录下： [hadoop@learn01 hadoop-2.7.6]$ pwd /opt/modules/hadoop-2.7.6 查看可以使用的命令及参数 $ bin/hdfs 格式化 $ bin/hdfs namenode -format 出现以下内容表示成功 18/06/01 11:41:16 INFO common.Storage: Storage directory /opt/modules/hadoop-2.7.6/data/dfs/name has been successfully formatted. 5) 启动hdfs守护进程 &gt; $ sbin/hadoop-daemon.sh start namenode //启动namenode进程 $ sbin/hadoop-daemon.sh start datanode //启动datanode 验证: $ jps 3097 Jps 2931 NameNode 3023 DataNode web访问界面 http://learn01.bigdata.com:50070/ HDFS shell的使用 $ bin/hdfs dfs -ls / $ bin/hdfs dfs -mkdir /input $ bin/hdfs dfs -mkdir -p /input/test/hellohdfs $ bin/hdfs dfs -rm -r /input $ bin/hdfs dfs -put ~/hello.txt /input 6) 配置YARN 任务调度 （Mapreduce） 资源管理（resourcemanager nodemanager）etc/hadoop目录下配置yarn-site.xml =======yarn-site.xml===== &lt;!-- 指定ResorceManager所在服务器的主机名 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;learn01.bigdata.com&lt;/value&gt; &lt;/property&gt; &lt;!-- 指明在执行MapReduce的时候使用shuffle --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; ==================================== 配置mapred-site.xml复制并重名模板文件 $ cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml =======mapred-site.xml===== &lt;!-- 指定MapReduce基于Yarn来运行 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; ===================================== 7) 启动hdfs yarn进程 $ sbin/hadoop-daemon.sh stop namenode $ sbin/hadoop-daemon.sh stop datanode $ sbin/hadoop-daemon.sh start namenode $ sbin/hadoop-daemon.sh start datanode $ sbin/yarn-daemon.sh start resourcemanager $ sbin/yarn-daemon.sh start nodemanager 查看进程启动 $ jps 6581 Jps 6406 DataNode 6347 NameNode 6507 NodeManager 6460 ResourceManager 通过web访问yarn http://learn01.bigdata.com:8088/cluster 8) 向yarn提交mapreduce任务圆周率计算 $ bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar pi 5 3","categories":[],"tags":[],"keywords":[]},{"title":"GitHub+Hexo 搭建个人网站详细教程","slug":"test-my-site-0","date":"2017-05-17T16:00:00.000Z","updated":"2018-05-23T02:04:05.739Z","comments":true,"path":"2017/05/18/test-my-site-0/","link":"","permalink":"http://yoursite.com/2017/05/18/test-my-site-0/","excerpt":"","text":"搭建步骤：1.GitHub创建个人仓库2.安装Git3.安装Node.js4.安装Hexo5.完成部署6.Hexo主题替换7.更换主题8.日常操作9.寻找图床 GitHub创建个人仓库注册Github,步骤：new repository创建新仓库-&gt;创建repository name 为你github用户名字一致的yourname.github.io 安装Git从Git官网下载 安装Node.jsNode.js下载地址注意安装Node.js会包含环境变量及npm的安装,安装后，检测Node.js是否安装成功，在命令行中输入1node -v 检测npm是否安装成功，在命令行中输入1npm -v 安装Hexo使用npm命令安装Hexo，输入：1npm install -g hexo-cli 安装完成后，在电脑新建一个空的文件夹,例如githubnet,右键打开git，输入：1git clone -b develop https://github.com/taohuaer/taohuaer.github.io.git 当前文件夹初始化我们的博客，输入：1hexo init blog 为了检测我们的网站雏形，分别按顺序输入以下三条命令：12hexo new test_my_site hexo s -p 5000 完成部署123hexo cleanhexo ghexo d Hexo主题替换进入Hexo选择喜欢的主题，按步骤就好了 日常操作参考Markdown语法写文章 寻找图床极简图床PicGo 参考知乎文章","categories":[{"name":"hexo博客","slug":"hexo博客","permalink":"http://yoursite.com/categories/hexo博客/"}],"tags":[{"name":"hexo博客","slug":"hexo博客","permalink":"http://yoursite.com/tags/hexo博客/"}],"keywords":[{"name":"hexo博客","slug":"hexo博客","permalink":"http://yoursite.com/categories/hexo博客/"}]}]}