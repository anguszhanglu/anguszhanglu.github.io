{"meta":{"title":"鹭岛","subtitle":"my zone,my rule","description":"zhanglu","author":"zhanglu","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2018-04-25T11:39:15.000Z","updated":"2018-04-25T11:39:15.270Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"Hadoop完全分布式搭建","slug":"Hadoop完全分布式搭建","date":"2018-06-06T11:52:14.000Z","updated":"2018-06-06T12:10:09.211Z","comments":true,"path":"2018/06/06/Hadoop完全分布式搭建/","link":"","permalink":"http://yoursite.com/2018/06/06/Hadoop完全分布式搭建/","excerpt":"","text":"集群规划 -&gt; 不同的守护进程运行哪些节点 linux01 linux02 linux03 HDFS Namenode SecondaryNamenode Datanode Datanode Datanode Yarn Nodemanager Nodemanager Nodemanager RecourceManager Histrory HistroryServer 一、基本环境准备CentOS 6.5 hadoop 2.7.6 jdk1.8 1 配置IP和DNS 映射 主机名//检查主机名 $ cat /etc/sysconfig/network //检查IP 和DNS 网关 配置静态IP $ cat /etc/sysconfig/network-scripts/ifcfg-eth0 //检查主机映射 $ cat /etc/hosts -&gt;Linux C:\\Windows\\System32\\drivers\\etc\\hosts -&gt;Windows 2 关闭防火墙及安全子系统# service iptables stop # chkconfig iptables off 检查： # service iptables status 会有提示iptables: Firewall is not running. # chkconfig --list | grep iptables 0:off 1:off 2:off 3:off 4:off 5:off 6:off 关闭Linux安全子系统 # vi /etc/sysconfig/selinux 为了提高性能，可以考虑将启动方式调整为不带桌面 sudo vi /etc/inittab id:3:initdefault: 3 创建普通用户名并密码, 配置sudo权限1 查看是否存在用户普通用户,没有就创建,稍后要保证3台帐号密码相同# useradd hadoop # passwd hadoop 或 # echo 123456 | passwd --stdin hadoop 2 配置hadoop的sudo权限4 安装jdk1 卸载自带jdk# rpm -qa | grep jdk # rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.50.1.11.5.el6_3.x86_64 # rpm -e --nodeps java-1.7.0-openjdk-1.7.0.9-2.3.4.1.el6_3.x86_64 2 在/opt下创建并修改权限modules/ software/ # mkdir /opt/modules /opt/software # chmod -R 777 modules/ software/ 3 安装jdk解压jdk到modules # tar -zxvf /home/hadoop/jdk-7u67-linux-x64.tar.gz -C /opt/modules/ 配置Java环境变量 # vi /etc/profile #添加以下内容 #JAVA_HOME export JAVA_HOME=/opt/modules/jdk1.7.0_67 export PATH=$PATH:$JAVA_HOME/bin 生效配置 # source /etc/profile 检查Java环境变量 # java -version 5 系统和软件【3台】如果时克隆出来的需要执行# vi /etc/udev/rules.d/70-persistent-net.rules 删除克隆来的信息(也就是eth0) 并把eth1改为eth0 # vi /etc/sysconfig/network-scripts/ifcfg-eth0 删除UUID 修改HWADDR=当前的mac地址(与70-persistent-net.rules的mac地址相同) 修改IPADDR为对应的ip 6 配置主机映射 【三台都需要需要添加】# vi /etc/hosts 192.168.239.211 bigdata01.hadoop.com 192.168.239.212 bigdata02.hadoop.com192.168.239.213 bigdata03.hadoop.com 7.修改主机名修改每台主机的主机名为对应的名字重启 8.windows的映射 (C:\\Windows\\System32\\drivers\\etc\\hosts)192.168.239.211 bigdata01.hadoop.com 192.168.239.212 bigdata02.hadoop.com192.168.239.213 bigdata03.hadoop.com ## 二、配置NTP服务 *.把linux01作为整个集群的时间同步服务器 *.集群中所有其他服务器都来这台服务器linux01同步时间 1.检查每台服务器所在的时区 $ date -R Thu, 23 Mar 2017 11:13:57 +0800 如果不是+0800,如要通过如下命令调整 # rm -rf /etc/localtime ---如果时区不是+0800 # ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 2.安装ntp服务# rpm -qa | grep ntp --查看ntp软件包是否已安装 ntp-4.2.6p5-1.el6.centos.x86_64 ntpdate-4.2.6p5-1.el6.centos.x86_64 如果没有以上两个,执行命令: yum -y install ntp (安装ntp) 3.修改ntp的配置文件（linux01.bigdata.com为第一台服务器的主机名,修改第一台）# vi /etc/ntp.conf 去掉第18行的# 修改成自己的网段 restrict 192.168.239.0 mask 255.255.255.0 nomodify notrap 注释掉以下几行（22行） #server 0.centos.pool.ntp.org iburst #server 1.centos.pool.ntp.org iburst #server 2.centos.pool.ntp.org iburst #server 3.centos.pool.ntp.org iburst CentsOS6.4 去掉第35 36行的注释 CentsOS6.5 36行去手动添加以下内容 server 127.127.1.0 #local clock fudge 127.127.1.0 stratum 10 4、同步服务器的时间（bigdata01.hadoop.com）# ntpdate 202.108.6.95 #操作这一步时关闭ntp服务 23 Mar 11:36:56 ntpdate[26856]: step time server 173.255.246.13 offset -12.240613 sec 5、启动ntp服务（默认式开始）PC1 root用户操作（bigdata01.hadoop.com） # service ntpd start # chkconfig ntpd on # chkconfig --list | grep ntpd ntpd 0:off 1:off 2:on 3:on 4:on 启动状态就可以了 # ntpdate 202.120.2.101 #测试 9 Jun 15:27:49 ntpdate[2689]: the NTP socket is in use, exiting #表示服务器1 作为时间服务器,同步时间不可用 #ntpd一旦开启就不能手动同步时间 6、如果另外两台的ntp的进程开启，那么需要关闭(对其他两台进行操作)# service --status-all | grep ntpd 查看ntpd服务是否开启 # chkconfig --list | grep ntpd 查看ntpd服务是否随开机启动 #如果服务可能开启 执行以下命令 # service ntpd stop # chkconfig ntpd off 7.第2、3台向第一台同步时间# ntpdate bigdata01.hadoop.com 18 Jan 23:01:34 ntpdate[2304]: step time server 192.168.239.211 offset -28768.643767 sec 8.制定周期性时间同步计划任务（PC2、PC3定时向PC1手动同步时间）在PC2 PC3每10分钟同步一次时间 # crontab -e */10 * * * * /usr/sbin/ntpdate bigdata01.hadoop.com [注意]：如果确实无法向第一台同步时间，请在交互窗口（可以同时设置3台时间）执行手动设置时间 # date -s &apos;2017/08/29 15:34:30&apos; 三、配置SSH免密钥登录切换为普通用户hadoop 使用普通用户操作 使用ssh登录的时候不需要用户名密码 $ sbin/start-dfs.sh 每个节点操作 $ ssh-keygen * 一直回车，生产当前主机的公钥和私钥(~/.ssh) //分发密钥（要向3台都发送） $ ssh-copy-id bigdata01.hadoop.com $ ssh-copy-id bigdata02.hadoop.com $ ssh-copy-id bigdata03.hadoop.com 测试: [hadoop@bigdata01 ~]$ ssh bigdata02.hadoop.com 测试失败，先删除.ssh目录，重做一遍 $ rm -r ~/.ssh 四、安装Hadoop1.下载上传到Linux并解压hadoop的.tar.gz$ tar -zxf hadoop-2.5.0.tar.gz -C /opt/modules/ 2.删除${HADOOP_HOME}/share/doc$ rm -rf doc/ 3.配置java环境支持在${HADOOP_HOME}/etc/hadoop在hadoop-env.sh mapred-env.sh yarn-env.sh中配置 JAVA_HOME=/opt/modules/jdk1.7.0_67 4. =======core-site.xml===&lt;!-- 指定第一台作为NameNode --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://bigdata01.hadoop.com:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/modules/hadoop-2.5.0/data&lt;/value&gt; &lt;/property&gt; 5. ============hdfs-site.xml===========&lt;!-- 分布式副本数设置为3 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;!-- secondarynamenode主机名 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;bigdata02.hadoop.com:50090&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode的web访问主机名:端口号 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address&lt;/name&gt; &lt;value&gt;bigdata01.hadoop.com:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- 关闭权限检查用户或用户组 --&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; 6.============mapred-site.xml============&lt;!-- 指定mapreducer向yarn提交 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;bigdata01.hadoop.com:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;bigdata01.hadoop.com:19888&lt;/value&gt; &lt;/property&gt; 7.==========yarn-site.xml============&lt;!-- 指定哪个节点作为resourcemanager --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;bigdata03.hadoop.com&lt;/value&gt; &lt;/property&gt; &lt;!-- 在mapreducer过程中启用shuffle --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 启用日志聚合 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 日志保存时间 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;86400&lt;/value&gt; &lt;/property&gt; =============================== 8配置slavesbigdata01.hadoop.com bigdata02.hadoop.com bigdata03.hadoop.com 【注意事项】：1.slaves中配置集群中所有的主机名 2.所有节点上的配置文件内容都是一样的 3.要按照集群规划配置所属进程 4.配置普通用户, 所有节点 有相同的帐号密码 四、分发(注意每个节点的权限问题： /opt/没有写权限)（bigdata01.hadoop.com）分发hadoop（已经配置好的）目录到其他两台(bigdata02和bigdata03)服务器上 scp -r bigdata01要复制的目录 bigdata02复制到的目录 $ scp -r /opt/modules/hadoop-2.5.0/ bigdata02.hadoop.com:/opt/modules/ $ scp -r /opt/modules/hadoop-2.5.0/ bigdata03.hadoop.com:/opt/modules/ 五、格式化Namenode在namenode所在的服务器linux01上,进行格式化${HADOOP_HOME}/bin $ bin/hdfs namendoe -format 【注意】1.先将PC1的hadoop配置目录分发到PC2和PC32.保证3台上的配置内容一模一样3.先确保将3台没有格式化信息4.最后格式化 六、启动进程在PC1上使用如下命令启动HDFS $ sbin/start-dfs.sh 在PC1上使用如下命令启动YARN $ sbin/start-yarn.sh 停止进程 在PC1上使用如下命令停止HDFS $ sbin/stop-dfs.sh 在PC3上使用如下命令停止YARN $ sbin/stop-yarn.sh ###【注意】修改任何配置文件，请先停止所有进程，然后重新启动 七、检查启动是否正常3台上jps查看进程，参考之前的集群规划 PC1:28626 DataNode28883 NodeManager28989 Jps28531 NameNode7527 ResourceManager PC2:7528 DataNode7826 Jps7717 NodeManager7583 SecondaryNameNode PC37622 NodeManager7922 Jps7405 DataNode","categories":[],"tags":[],"keywords":[]},{"title":"伪分布搭建","slug":"伪分布搭建","date":"2017-06-06T10:58:01.000Z","updated":"2018-06-06T11:46:50.017Z","comments":true,"path":"2017/06/06/伪分布搭建/","link":"","permalink":"http://yoursite.com/2017/06/06/伪分布搭建/","excerpt":"","text":"伪分布的搭建环境准备1) 网络配置(主机名, 映射文件(服务器的, windows,), ip) 2) 关闭防火墙及安全子系统 3) 安装jdk 切换为普通用户 sudo chmod 777 /opt 创建/opt/modules /opt/software 搭建伪分布1) 解压安装hadoop【注意上传和解压过程中的用户权限问题】$ tar -zxvf /opt/software/hadoop-2.7.6.tar.gz -C /opt/modules/ 2) 配置hadoop的java环境支持， etc/hadoop目录下hadoop-env.sh mapred-env.sh yarn-env.sh 在这3个文件中都配置 export JAVA_HOME=/opt/modules/jdk1.8.0_112 3) 与hdfs相关的配置 etc/hadoopI）core-site.xml =============core-site.xml=================== &lt;!-- NameNode地址，访问入口 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://learn01.bigdata.com:8020&lt;/value&gt; &lt;/property&gt; &lt;!-- hadoop在运行时产生的文件，元数据在本地的存放目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/modules/hadoop-2.7.6/data&lt;/value&gt; &lt;/property&gt; ============================================ II) hdfs-site.xml =============hdfs-site.xml============ &lt;!--存放到hdfs上的文件的副本数，伪分布式配置为1 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; ====================================== 4) 格式化namenode只格式化一遍在${HADOOP_HOME}目录下： [hadoop@learn01 hadoop-2.7.6]$ pwd /opt/modules/hadoop-2.7.6 查看可以使用的命令及参数 $ bin/hdfs 格式化 $ bin/hdfs namenode -format 出现以下内容表示成功 18/06/01 11:41:16 INFO common.Storage: Storage directory /opt/modules/hadoop-2.7.6/data/dfs/name has been successfully formatted. 5) 启动hdfs守护进程 &gt; $ sbin/hadoop-daemon.sh start namenode //启动namenode进程 $ sbin/hadoop-daemon.sh start datanode //启动datanode 验证: $ jps 3097 Jps 2931 NameNode 3023 DataNode web访问界面 http://learn01.bigdata.com:50070/ HDFS shell的使用 $ bin/hdfs dfs -ls / $ bin/hdfs dfs -mkdir /input $ bin/hdfs dfs -mkdir -p /input/test/hellohdfs $ bin/hdfs dfs -rm -r /input $ bin/hdfs dfs -put ~/hello.txt /input 6) 配置YARN 任务调度 （Mapreduce） 资源管理（resourcemanager nodemanager）etc/hadoop目录下配置yarn-site.xml =======yarn-site.xml===== &lt;!-- 指定ResorceManager所在服务器的主机名 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;learn01.bigdata.com&lt;/value&gt; &lt;/property&gt; &lt;!-- 指明在执行MapReduce的时候使用shuffle --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; ==================================== 配置mapred-site.xml复制并重名模板文件 $ cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml =======mapred-site.xml===== &lt;!-- 指定MapReduce基于Yarn来运行 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; ===================================== 7) 启动hdfs yarn进程 $ sbin/hadoop-daemon.sh stop namenode $ sbin/hadoop-daemon.sh stop datanode $ sbin/hadoop-daemon.sh start namenode $ sbin/hadoop-daemon.sh start datanode $ sbin/yarn-daemon.sh start resourcemanager $ sbin/yarn-daemon.sh start nodemanager 查看进程启动 $ jps 6581 Jps 6406 DataNode 6347 NameNode 6507 NodeManager 6460 ResourceManager 通过web访问yarn http://learn01.bigdata.com:8088/cluster 8) 向yarn提交mapreduce任务圆周率计算 $ bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar pi 5 3","categories":[],"tags":[],"keywords":[]},{"title":"GitHub+Hexo 搭建个人网站详细教程","slug":"test-my-site-0","date":"2017-05-17T16:00:00.000Z","updated":"2018-05-23T02:04:05.739Z","comments":true,"path":"2017/05/18/test-my-site-0/","link":"","permalink":"http://yoursite.com/2017/05/18/test-my-site-0/","excerpt":"","text":"搭建步骤：1.GitHub创建个人仓库2.安装Git3.安装Node.js4.安装Hexo5.完成部署6.Hexo主题替换7.更换主题8.日常操作9.寻找图床 GitHub创建个人仓库注册Github,步骤：new repository创建新仓库-&gt;创建repository name 为你github用户名字一致的yourname.github.io 安装Git从Git官网下载 安装Node.jsNode.js下载地址注意安装Node.js会包含环境变量及npm的安装,安装后，检测Node.js是否安装成功，在命令行中输入1node -v 检测npm是否安装成功，在命令行中输入1npm -v 安装Hexo使用npm命令安装Hexo，输入：1npm install -g hexo-cli 安装完成后，在电脑新建一个空的文件夹,例如githubnet,右键打开git，输入：1git clone -b develop https://github.com/taohuaer/taohuaer.github.io.git 当前文件夹初始化我们的博客，输入：1hexo init blog 为了检测我们的网站雏形，分别按顺序输入以下三条命令：12hexo new test_my_site hexo s -p 5000 完成部署123hexo cleanhexo ghexo d Hexo主题替换进入Hexo选择喜欢的主题，按步骤就好了 日常操作参考Markdown语法写文章 寻找图床极简图床PicGo 参考知乎文章","categories":[{"name":"hexo博客","slug":"hexo博客","permalink":"http://yoursite.com/categories/hexo博客/"}],"tags":[{"name":"hexo博客","slug":"hexo博客","permalink":"http://yoursite.com/tags/hexo博客/"}],"keywords":[{"name":"hexo博客","slug":"hexo博客","permalink":"http://yoursite.com/categories/hexo博客/"}]}]}